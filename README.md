# Let's explore Spark DataFrames

Dataframe analysis in PySpark!
<!--
Let's build some dataframes so that we have something with which to work.
We'll do some basic reading, writing, partitioning and maybe discuss certain
parameter advantages and disadvantages. -->

[Configs:](./pages/configs/Configs.md) Initial Configuration / Spark settings for your Jupyter notebook!

[Basics:](./pages/basics/Basics.md) Read, write, generate a sample DF!
In case you don't have big data sets, build some quickly! Let's get some standard reading, writing and partitioning examples down.

[Analysis:](pages/analysis/Analysis.md)
Let's do some common dataframe manipulations. I'll show what I expect are some
common column formatting issues, occurrences, and operations you're likely to see.
We'll cover aggregations, grouping, and ordering.

[Transformations:](pages/transformations/Transformations.md) (coming soon!)

[Joins:](pages/joins/Joins.md) Join!

<!-- [Intermediate:](pages/intermediate) (coming soon!) -->

<!-- <br>
## In Progress / still under development:
 [Basic Operations](notebooks\incomplete\dev_basic_ops_2dataframes.html)

 [Build examples](notebooks\incomplete\examples_build_dataframe.html)

 [More Build Examples](notebooks\incomplete\dev_build_dataframe.html)

 [For Loop Write & Check](notebooks\incomplete\dev_ForLoopWriteCheck.html)

 [Read Write Partition](notebooks\incomplete\dev_read_write_partition.html)
 -->

<!-- [(home)](https://dmerz75.github.io/spark2_dfanalysis)
[(git-home)](https://github.com/dmerz75/spark2_dfanalysis) -->
<!-- [Iridium](https://dmerz75.github.io/iridium_catalyst/) for details. -->
<!-- ## Start Spark | Construct Dataframes | Read/Write -->
